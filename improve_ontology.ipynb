{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "from orangecontrib.bio.ontology import OBOOntology\n",
    "import networkx as nx\n",
    "%matplotlib inline\n",
    "from pylab import * \n",
    "from itertools import repeat\n",
    "%aimport network_tools\n",
    "from network_tools import *\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve ontology\n",
    "Starting off with the 'human_samples' network from `explore_ontology.py` I will improve the annotation:\n",
    "* group singletons that are the same sample but replicates/from different donors\n",
    "* add 'cell_line' / 'primary cell' / .. annotation from supplementary information\n",
    "* ...\n",
    "\n",
    "Moreover, I will start to cluster the samples to get an overview which cell signatures we want to generate and are biologically meaningful. \n",
    "\n",
    "### What do we have in the F5 dataset\n",
    "From the F5 paper (Nature 2014): \n",
    "* 573 human primary cell samples (3 donors for most cell types) \n",
    "* 128 mouse primary cell samples\n",
    "* 250 cancer cell lines\n",
    "* 152 human post-mortem-tissues\n",
    "* 271 mouse developmental tissue samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1374"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "573+128+250+152+271"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check human_samples network\n",
    "* Does it contain all (human) samples? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obo = OBOOntology()\n",
    "obo.load(open(\"data/ff-phase2-140729.obo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hsa_samples = relabel_nodes(obo, build_tree(obo, \"FF:0000210\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network also contains a lot of 'annotation' nodes that do not represent a sample. Samples have an ID FF:?????-?????."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contained_samples = [s for s in hsa_samples.nodes() if re.match(r'FF:(.{5})-(.{5})', s) is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_vars = pd.read_csv(\"data/column_vars.processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_obo_ids = set(col_vars[\"obo_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hsa_obo_ids = set([x.split()[0][:-1] for x in hsa_samples.nodes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes in network:  2298\n",
      "number of samples in network:  1800\n",
      "number of samples in data table:  1816\n",
      "intersection:  1800\n"
     ]
    }
   ],
   "source": [
    "print(\"number of nodes in network: \", len(hsa_obo_ids))\n",
    "print(\"number of samples in network: \", len(contained_samples))\n",
    "print(\"number of samples in data table: \", len(col_obo_ids))\n",
    "print(\"intersection: \", len(col_obo_ids & hsa_obo_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means that all 1800 human samples in the network are contained in the datatable. \n",
    "However, 16 samples are in the data table that are not annotated as human sample in the ontology: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FF:10150-102I6: medial frontal gyrus, adult, donor10252',\n",
       " 'FF:11914-125G6: CD4+CD25-CD45RA- memory conventional T cells expanded, donor2',\n",
       " 'FF:11915-125G7: CD4+CD25+CD45RA+ naive regulatory T cells expanded, donor2',\n",
       " 'FF:11918-125H1: CD4+CD25-CD45RA- memory conventional T cells expanded, donor3',\n",
       " 'FF:11919-125H2: CD4+CD25+CD45RA+ naive regulatory T cells expanded, donor3',\n",
       " 'FF:11937-126A2: gamma delta positive T cells, donor1',\n",
       " 'FF:11938-126A3: gamma delta positive T cells, donor2',\n",
       " 'FF:11939-126A4: Mast cell, expanded, donor5',\n",
       " 'FF:11940-126A5: Mast cell, expanded and stimulated, donor5',\n",
       " 'FF:11941-126A6: Mast cell, expanded, donor8',\n",
       " 'FF:11942-126A7: Mast cell, expanded and stimulated, donor8',\n",
       " 'FF:13364-143F7: HES3-GFP Embryonic Stem cells, cardiomyocytic induction, day00, biol_rep1 (UH-1)',\n",
       " 'FF:13365-143F8: HES3-GFP Embryonic Stem cells, cardiomyocytic induction, day00, biol_rep2 (UH-2)',\n",
       " 'FF:13424-144D4: iPS differentiation to neuron, control donor C11-CRL2429, day18, rep1',\n",
       " 'FF:13432-144E3: iPS differentiation to neuron, control donor C11-CRL2429, day18, rep3',\n",
       " 'FF:13464-144H8: iPS differentiation to neuron, down-syndrome donor C18-CCL54, day18, rep2']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([tag2name(obo, n) for n in col_obo_ids.difference(hsa_obo_ids)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the network, one can find that most of the samples have simply been forgotten:\n",
    "`FF:13364-143F7: HES3-GFP Embryonic Stem cells, cardiomyocytic induction, day00, biol_rep1 (UH-1)` fits perfectly to `FF:13366-143F9: HES3-GFP Embryonic Stem cells, cardiomyocytic induction, day00, biol_rep3 (UH-3)` which exists as a singleton in the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating the missing values in the network\n",
    "We will now manually correct the ontology:\n",
    "* Add the missing entries\n",
    "* group the singletons by name (if they are the same sample but replicates/from different donors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find inconsitencies between name and Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## i'm particularily interested in donor/replicate information that is not part of the ontology. \n",
    "## This could be helpful for grouping singletons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add sample type information from supplementary Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "si_table = pd.read_excel(\"data/fantom5-S1.xls\", sheetname=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We tried our very best to fix the bugs in the annotation, however it is unlikely that my analasis reveals and corrected all mistakes. So in a next step we have to do some computational outlier detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
